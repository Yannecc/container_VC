#!/bin/bash

IMG_TO_RUN="dev"
TAG_TO_USE="latest"
GPU_TO_USE=0
while getopts "i:t:g:" opt; do
  case ${opt} in
    i ) IMG_TO_RUN=$OPTARG;;
    t ) TAG_TO_USE=$OPTARG;;
    g ) GPU_TO_USE=$OPTARG;;
    \?) echo "Wrong usage: runDocker [-i] [-t] [-g]"; exit 1;;
  esac
done


PRETRAINED_MODELS_WEIGHTS="
    -v $HOME/.cache/torch:/home/user/.cache/torch 
    -v $HOME/.torch:/home/user/torch
"

DATASETS_FOLDERS="
    -v /opt/datasets:/opt/datasets
"


ALPINE_INTUITION_FOLDER="
    -v $HOME/alpine_intuition:/home/user/alpine_intuition
"


if [[ "$IMG_TO_RUN" == "dev" ]]; then
    IMG_TO_RUN=${IMG_TO_RUN}_$UID
fi
IMG="alpine-intuition/$IMG_TO_RUN"


if [ -z "$(docker images -q "$IMG":"$TAG_TO_USE")" ]; then
    echo "The image '$IMG:$TAG_TO_USE' do not exist"
    exit 1
fi
echo "Docker image to run: $IMG:$TAG_TO_USE"


ALP_DEV_ID=1010


# Define runtime and GPU(s) to use

if ! [ -x "$(command -v lspci)" ]; then
    echo "> 'lspci' package needed, please install it before run"
    exit 1
fi
NUM_GPUS=$(lspci | grep -c "VGA.*NVIDIA")

if [[ "$NUM_GPUS" -gt 0 ]]; then
    if [[ $GPU_TO_USE -gt $NUM_GPUS-1 ]]; then
        echo "You want use GPU #$GPU_TO_USE but there is" \
            "only $NUM_GPUS GPUS available (indexing start at #0)."
        exit 1
    fi

    if [ "$GPU_TO_USE" -eq -1 ]; then
        echo "ALL GPU USED"
        GPU="all"
    else
        echo "GPU #$GPU_TO_USE USED"
        GPU="device=${GPU_TO_USE}"
    fi
    RUNTIME="--runtime=nvidia --gpus $GPU"
else
    RUNTIME=""
    echo "No NVIDIA GPU found. Switching to standard runtime"
fi


docker run \
    -it \
    --ipc=host \
    --shm-size=30G \
    --user=$UID:$ALP_DEV_ID \
    $RUNTIME \
    $PRETRAINED_MODELS_WEIGHTS \
    $DATASETS_FOLDERS \
    $ALPINE_INTUITION_FOLDER \
    $IMG \
    /bin/bash
